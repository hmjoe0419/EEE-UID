{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520556ee-1448-426a-a96a-87cba5d2eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\haris\\Downloads\\Augmented_DNP3_Parser_Training(3).xls\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove leading and trailing spaces from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Select only numerical features, excluding unwanted columns\n",
    "features = data.select_dtypes(include=['float64', 'int64']).drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'Label'], errors='ignore')\n",
    "labels = data['Label'].apply(lambda x: 0 if x == 'NORMAL' else 1)  # Encode labels (0 for NORMAL, 1 for anomaly)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply Principal Component Analysis (PCA) for dimensionality reduction\n",
    "pca = PCA(n_components=20, random_state=42)  # Reduce to 20 principal components\n",
    "X_train_reduced = pca.fit_transform(X_train_scaled)\n",
    "X_test_reduced = pca.transform(X_test_scaled)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 21), pca.explained_variance_ratio_, marker='o', linestyle='dashed')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.show()\n",
    "\n",
    "# Initialize and train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Function to filter dataset based on intrusion rate\n",
    "def filter_intrusion_rate(data, rate):\n",
    "    normal_data = data[data['Label'] == 'NORMAL']\n",
    "    anomalous_data = data[data['Label'] != 'NORMAL']\n",
    "    num_anomalous = int(len(normal_data) * rate / 100)\n",
    "    num_anomalous = min(num_anomalous, len(anomalous_data))  # Ensure we do not exceed available anomalies\n",
    "    sampled_anomalous_data = anomalous_data.sample(n=num_anomalous, random_state=42)\n",
    "    return pd.concat([normal_data, sampled_anomalous_data]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Define intrusion rates for analysis\n",
    "intrusion_rates = [1, 3, 5, 7]\n",
    "results = {}\n",
    "\n",
    "# Evaluate model performance at different intrusion rates\n",
    "for rate in intrusion_rates:\n",
    "    filtered_data = filter_intrusion_rate(data, rate)\n",
    "    X_train_filtered = filtered_data.select_dtypes(include=['float64', 'int64']).drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'Label'], errors='ignore')\n",
    "    y_train_filtered = filtered_data['Label'].apply(lambda x: 0 if x == 'NORMAL' else 1).values\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "        X_train_filtered, y_train_filtered, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Apply standard scaling and PCA transformation\n",
    "    X_train_scaled_filtered = scaler.transform(X_train_filtered)\n",
    "    X_test_scaled_filtered = scaler.transform(X_test_filtered)\n",
    "    X_train_reduced_filtered = pca.transform(X_train_scaled_filtered)\n",
    "    X_test_reduced_filtered = pca.transform(X_test_scaled_filtered)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_filtered = rf_model.predict(X_test_reduced_filtered)\n",
    "    y_proba_pred_filtered = rf_model.predict_proba(X_test_reduced_filtered)[:, 1]\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "    precision_filtered = precision_score(y_test_filtered, y_pred_filtered)\n",
    "    recall_filtered = recall_score(y_test_filtered, y_pred_filtered)\n",
    "    f1_filtered = f1_score(y_test_filtered, y_pred_filtered)\n",
    "    roc_auc_filtered = roc_auc_score(y_test_filtered, y_proba_pred_filtered)\n",
    "    conf_matrix = confusion_matrix(y_test_filtered, y_pred_filtered)\n",
    "\n",
    "    # Store results\n",
    "    results[rate] = {\n",
    "        'Accuracy': accuracy_filtered,\n",
    "        'Precision': precision_filtered,\n",
    "        'Recall': recall_filtered,\n",
    "        'F1 Score': f1_filtered,\n",
    "        'ROC-AUC': roc_auc_filtered,\n",
    "        'Confusion Matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix for {rate}% Intrusion Rate')\n",
    "    plt.show()\n",
    "\n",
    "# Print evaluation results\n",
    "for rate, metrics in results.items():\n",
    "    print(f\"\\nIntrusion Rate: {rate}%\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "    print(f\"ROC-AUC: {metrics['ROC-AUC']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics['Confusion Matrix'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
